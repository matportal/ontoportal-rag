# -----------------------------------------------------------------------------
# Core Application Settings
# -----------------------------------------------------------------------------
# Set to "development" or "production"
APP_ENV=development

# -----------------------------------------------------------------------------
# External Service Credentials
# -----------------------------------------------------------------------------
# Weaviate Configuration
WEAVIATE_URL=http://weaviate:8080
# For Weaviate Cloud, provide your API key. For local Docker, this can be ignored.
WEAVIATE_API_KEY=your-weaviate-api-key

# Cohere API Key for re-ranking
COHERE_API_KEY=your-cohere-key
# Optional: Override Cohere API base URL (useful for gateways/proxies)
# COHERE_BASE_URL=https://api.cohere.com

# OpenAI API Key for generation (or any other LLM provider)
OPENAI_API_KEY=your-llm-key
# Optional: Override OpenAI API base URL (e.g., LiteLLM proxy)
# OPENAI_BASE_URL=http://host.docker.internal:4000/v1

# Optional: Provide separate credentials/base URL for embeddings provider
# OPENAI_EMBEDDINGS_API_KEY=your-embeddings-key
# OPENAI_EMBEDDINGS_BASE_URL=http://host.docker.internal:4000/v1

# -----------------------------------------------------------------------------
# Celery and Redis Configuration
# -----------------------------------------------------------------------------
# URL for the Redis instance used as a message broker and result backend
REDIS_URL=redis://redis:6379/0
CELERY_BROKER_URL=redis://redis:6379/0
CELERY_RESULT_BACKEND=redis://redis:6379/0

# -----------------------------------------------------------------------------
# Model Configuration
# -----------------------------------------------------------------------------
# Specify the models to be used in the pipelines
DEFAULT_LLM_MODEL=gpt-4o
DEFAULT_RERANKING_MODEL=rerank-english-v2.0
EMBEDDING_MODEL=text-embedding-3-small
WEAVIATE_CLASS_NAME=OntologyChunk
